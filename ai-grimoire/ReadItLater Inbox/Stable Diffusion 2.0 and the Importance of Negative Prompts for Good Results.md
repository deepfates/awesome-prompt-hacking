[[ReadItLater]] [[Article]]

# [Stable Diffusion 2.0 and the Importance of Negative Prompts for Good Results](https://minimaxir.com/2022/11/stable-diffusion-negative-prompt/)

As an unexpected surprise, StabilityAI released [Stable Diffusion 2.0](https://stability.ai/blog/stable-diffusion-v2-release) last week, the next major version of the text-to-image AI that has been warping the entire ecosystem. Architecture-wise it‚Äôs mostly the same, except with a new text encoder ([OpenCLIP](https://github.com/mlfoundations/open_clip) instead of [OpenAI](https://openai.com/)‚Äôs CLIPText). StabilityAI boasts that Stable Diffusion 2.0 has [better performance quantitatively](https://github.com/Stability-AI/stablediffusion#stable-diffusion-v20), but art in the end is subjective.

Within 24 hours after release, users on [Reddit](https://www.reddit.com/) and [Twitter](https://twitter.com/) noted that the new model performed *worse* than Stability Diffusion 1.5 with the same exact input prompts and settings. Some users also noticed that putting in the names of real artists such as the [infamous Greg Rutkowski](https://thechainsaw.com/nft/ai-art-debate/) had zero effect on the output.

Some point to the fact that the new model was trained on fewer NSFW images as the culprit for these changes, but in my opinion the culprit here is the switch to OpenCLIP. A new text encoder means some of the assumptions and prompt hacks for earlier versions of Stable Diffusion may no longer work. On the other hand, it may enable *new* prompt hacks. The CEO of StabilityAI Emad Mostaque [mentioned](https://twitter.com/EMostaque/status/1596907328548139008) that negative prompts should work better due to the way the model was trained. It‚Äôs still theory though; practice and experimentation is always better.

I hadn‚Äôt played with negative prompts in Stable Diffusion before, although it is rumored that it‚Äôs part of the secret sauce behind some of the more well known commercial Stable Diffusion services. But after lots of experimenting with negative prompts in SD 2.0, it‚Äôs clear that negative prompts are the key to getting good results from the model reliably, and most surprisingly, negative prompts can be far superior than traditional prompt additions.

## An Introduction to Negative Prompting

All generated images in this blog post are generated by Stable Diffusion v2.0 base (via [diffusers](https://github.com/huggingface/diffusers)) with a classifier-free guidance of 7.5, the Euler Ancestral scheduler, with 50 denoising steps.

Analogous with normal text-to-image prompting, negative prompting indicates which terms you do not want to see in the resulting image. At a technical level for Stable Diffusion, the encoded negative prompt serves as an high-dimension anchor the diffusion process strays away from.

Let‚Äôs test it out with Stable Diffusion 2.0. For example, let‚Äôs go back to my [VQGAN + CLIP prompts](https://minimaxir.com/2021/08/vqgan-clip/) and try `cyberpunk forest by Salvador Dali`.

![prompt: `cyberpunk forest by Salvador Dali`, via Stable Diffusion 2.0](ReadItLater%20Inbox/assets/prompt%20`cyberpunk%20forest%20by%20Salvador%20Dali`,%20via%20Stable%20Diffusion%202.0.png)

prompt: `cyberpunk forest by Salvador Dali`, via Stable Diffusion 2.0

What if you wanted to remove things like `trees` and/or a certain color like `green`? That‚Äôs what you‚Äôd put in your negative prompt. Can Stable Diffusion 2.0 adjust?

![prompt: `cyberpunk forest by Salvador Dali`; negative prompt: `trees, green`, via Stable Diffusion 2.0](ReadItLater%20Inbox/assets/prompt%20`cyberpunk%20forest%20by%20Salvador%20Dali`;%20negative%20prompt%20`trees,%20green`,%20via%20Stable%20Diffusion%202.0.png)

prompt: `cyberpunk forest by Salvador Dali`; negative prompt: `trees, green`, via Stable Diffusion 2.0

Indeed it does, with a larger dose of surrealistic cyberpunk, but it is still a forest albeit more metaphorical.

One popular trick is to also include more abstract bad-image concepts like `blurry` and `pixelated` in order to theoretically improve the image. But are these negative prompts better than the prompt additional ‚Äúingredients‚Äù like `4k hd` and `trending on artstation` like CLIPText-based text-to-image AI before it? How do negative prompts interact with those positive prompt additions? Let‚Äôs test this further and more empirically.

## In The Style of Wrong

As a quick aside, textual inversion, a technique which allows the text encoder to learn a specific object or style that can be trivially invoked in a prompt, does work with Stable Diffusion 2.0, although since the text encoder is different (and larger, with 1024D embeddings instead of 768D), each textual inversion embedding has to be retrained but otherwise behaves the same way. One popular style in SD 1.X is the ‚Äú[Midjourney](https://www.midjourney.com/)‚Äù style located [here](https://huggingface.co/sd-concepts-library/midjourney-style), which has a overly-fantasy aesthetic. I‚Äôve trained a new version of the `<midjourney>` token (available [here](https://huggingface.co/minimaxir/midjourney_sd_2_0)).

Additionally, there‚Äôs a new possibility of using textual inversion for negative prompts. Redditor Nerfgun3 trained a ‚Äú[negative embedding](https://www.reddit.com/r/StableDiffusion/comments/yy2i5a/i_created_a_negative_embedding_textual_inversion/)‚Äù for SD 1.X by generating a dataset of synthetic images by using common negative prompts as positive prompts instead, then training a textual inversion embedding on them. I [reproduced that process](https://github.com/minimaxir/stable-diffusion-negative-prompt/blob/main/wrong_image_generator.ipynb) with a few tweaks to improve the synthetic dataset and trained a new `<wrong>` token (available [here](https://huggingface.co/minimaxir/wrong_embedding_sd_2_0)).

We can now cross-test a positive prompt addition or a positive token with a negative prompt or negative token to see just how impactful the negative prompts are. Here a list of prompts to test, with positive prompt additions in green and negative prompt additions in red:

| Label | Description |
| --- | --- |
| `PROMPT` | hyper-detailed and intricate, realistic shaded, fine detail, realistic proportions, symmetrical, sharp focus, 8K resolution |
| `<TOKEN>` | in the style of `<midjourney>` |
| `PROMPT` | ugly, boring, bad anatomy |
| `<TOKEN>` | in the style of `<wrong>` |

For example, one test input to Stable Diffusion 2.0 could be a prompt of `cyberpunk forest by Salvador Dali, in the style of <midjourney>` and a negative prompt of `in the style of <wrong>`, corresponding a green `<TOKEN>` prompt label and a red `<TOKEN>` label respectively.

Additionally, each individual generated image will start with the same initial latent, with seeded scheduling. This allows the impacts of negative prompts to be shown more clearly, as keeping the same prompt given a constant initial latent will allow the generated image composition to remain the same while changing the negative prompts.

Now, let‚Äôs finally begin. Let‚Äôs start off with `Steve Jobs head` as the base prompt; simple enough.

![base prompt: `Steve Jobs head`, seed: 59049, via Stable Diffusion 2.0](ReadItLater%20Inbox/assets/base%20prompt%20`Steve%20Jobs%20head`,%20seed%2059049,%20via%20Stable%20Diffusion%202.0.png)

base prompt: `Steve Jobs head`, seed: 59049, via Stable Diffusion 2.0

The two prompt additions each changed the style; the base prompt did a cartoon; the realistic prompt addition made it more of a 3D render, and the Midjourney token made it an artsy approach. However, when negative prompts are added, each image becomes more clear, with less blurriness, more neutral lighting, and greater skin detail. More notably, the `<wrong>` token did much better than the smaller negative prompt.

How about an image generation classic: the famous avocado armchair which was demoed with the [original DALL-E](https://openai.com/blog/dall-e/)?

![base prompt: `an armchair in the shape of an avocado. an armchair imitating an avocado.`, seed: 59049, via Stable Diffusion 2.0](ReadItLater%20Inbox/assets/base%20prompt%20`an%20armchair%20in%20the%20shape%20of%20an%20avocado.%20an%20armchair%20imitating%20an%20avocado.`,%20seed%2059049,%20via%20Stable%20Diffusion%202.0.png)

base prompt: `an armchair in the shape of an avocado. an armchair imitating an avocado.`, seed: 59049, via Stable Diffusion 2.0

Here‚Äôs where things get interesting; the positive text prompt addition ruins the intent of the original prompt completely, and again the negative prompts each refine the corresponding image with more detail (including the whole avocado!)

Now that we have good demos, let‚Äôs go back to Dali‚Äôs cyberpunk forest:

![base prompt: `cyberpunk forest by Salvador Dali`, seed: 59049, via Stable Diffusion 2.0](ReadItLater%20Inbox/assets/base%20prompt%20`cyberpunk%20forest%20by%20Salvador%20Dali`,%20seed%2059049,%20via%20Stable%20Diffusion%202.0.png)

base prompt: `cyberpunk forest by Salvador Dali`, seed: 59049, via Stable Diffusion 2.0

In this case, both positive prompt additions wipe out Dali‚Äôs style, opting for a more realistic forest and later reinforced by the negative prompts. In the case of the original prompt, the negative prompts further emphasize Dali‚Äôs artistic style. This a good example of positive prompt additions not being a strictly good thing.

Can negative prompts help create yummy AI-generated food [like DALL-E 2 can](https://minimaxir.com/2022/07/food-photography-ai/)? Let‚Äôs see if it can make a hamburger:

![base prompt: `a delicious hamburger`, seed: 19683, via Stable Diffusion 2.0](ReadItLater%20Inbox/assets/base%20prompt%20`a%20delicious%20hamburger`,%20seed%2019683,%20via%20Stable%20Diffusion%202.0.png)

base prompt: `a delicious hamburger`, seed: 19683, via Stable Diffusion 2.0

This one is a pretty unambigious case of negative prompts helping out the final result; the output using both tokens is pretty close to DALL-E 2 quality!

Another interesting thing about Stable Diffusion 2.0 is that text renders better; small text is not fully legible, but large text is more discernable. Perhaps Stable Diffusion 2.0 can envision a [New York Times](https://www.nytimes.com/) front page depicting the rise of robot overlords.

![base prompt: `an evil robot on the front page of the New York Times`, seed: 19683, via Stable Diffusion 2.0](ReadItLater%20Inbox/assets/base%20prompt%20`an%20evil%20robot%20on%20the%20front%20page%20of%20the%20New%20York%20Times`,%20seed%2019683,%20via%20Stable%20Diffusion%202.0.png)

base prompt: `an evil robot on the front page of the New York Times`, seed: 19683, via Stable Diffusion 2.0

There‚Äôs a surprising amount of evil robot variety despite the fixed latent inputs, and the layouts of the newspaper are very accurate to the NYT. The especially weird negative-prompt-text-only image is an example of a surprisingly rare mode collapse, which is interesting (or it‚Äôs Stable Diffusion *hiding something*). Although the robot from the original prompt is clearly the most evil.

We can also investigate how negative prompts can help the rendering of human subjects. Let‚Äôs take [Taylor Swift](https://www.taylorswift.com/). What happens when she becomes President Taylor Swift? (hopefully Stable Diffusion doesn‚Äôt confuse her with the other [President Taylor](https://en.wikipedia.org/wiki/Zachary_Taylor))

![base prompt: `President Taylor Swift giving her presidential inauguration speech`, seed: 6561, via Stable Diffusion 2.0](ReadItLater%20Inbox/assets/base%20prompt%20`President%20Taylor%20Swift%20giving%20her%20presidential%20inauguration%20speech`,%20seed%206561,%20via%20Stable%20Diffusion%202.0.png)

base prompt: `President Taylor Swift giving her presidential inauguration speech`, seed: 6561, via Stable Diffusion 2.0

So both the positive prompt addition types make the initial output unambigiously worse, which is a surprise. But the negative prompts fix them, and again, give President Tay a nice wardrobe varity. It‚Äôs worth noting that Stable Diffusion 2.0 is better at generating correct hands than SD 1.X‚Ä¶just don‚Äôt look at them too closely.

Lastly, we can‚Äôt forget about [Ugly Sonic](https://knowyourmeme.com/memes/ugly-sonic), the initial hedgehog from the Sonic Movie who was the subject of my [previous Stable Diffusion blog post](https://minimaxir.com/2022/09/stable-diffusion-ugly-sonic/). I received many complaints that the AI-generated Ugly Sonic wasn‚Äôt really Ugly Sonic because the generated Ugly Sonics didn‚Äôt have human teeth! Time to fix that!

![base prompt: ` smiling with human teeth`, seed: 6561, via Stable Diffusion 2.0](ReadItLater%20Inbox/assets/base%20prompt%20`%20smiling%20with%20human%20teeth`,%20seed%206561,%20via%20Stable%20Diffusion%202.0.png)

base prompt: `<ugly-sonic> smiling with human teeth`, seed: 6561, via Stable Diffusion 2.0

In this case, the negative prompts *ruined* Ugly Sonic because they progressively remove his human teeth!

## Conclusion

As always with AI art, your mileage will vary, but negative prompting will be a much more important tool going forward in AI Image generation and anchoring on prompt engineering strategies that worked in the past is a mistake. It also provides a good opportunity to stop using living artists as a prompt engineering crutch since that may not be possible moving forward, which is a good thing for the industry (especially given [legal uncertainty](https://www.theverge.com/23444685/generative-ai-copyright-infringement-legal-fair-use-training-data)!).

All my code used to generate the images for this article are available [in this GitHub repository](https://github.com/minimaxir/stable-diffusion-negative-prompt), including a [Colab Notebook](https://colab.research.google.com/github/minimaxir/stable-diffusion-negative-prompt/blob/main/sd_2_0_base.ipynb) for general generation with the `<wrong>` token and a [Colab Notebook](https://colab.research.google.com/github/minimaxir/stable-diffusion-negative-prompt/blob/main/sd_2_0_grid_3x3.ipynb) for the 3x3 labeled grid images, with easily tweakable prompt inputs if you want to run your own experiments.

It would be interesting to see if it‚Äôs possible to finetune Stable Diffusion 2.0 such that it gains an ‚Äúintrinsic‚Äù negative prompt without having to manually specify it‚Ä¶which might be happening sooner than you think. üòâ

---

*Disclosure: I am neither an artist nor an expert in art theory. All my comments on what are ‚Äúgood‚Äù AI art generations are my own (likely bad) opinions.*

If you liked this post, I have set up a **[Patreon](https://www.patreon.com/minimaxir)** to fund my machine learning/deep learning/software/hardware needs for my future crazy yet cool projects, and any monetary contributions to the Patreon are appreciated and will be put to good creative use.